{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffc32fa8",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "This notebook aims to develop and evaluate a model to predict diamond prices given data in the proposed format ([diamond dataset](datasets/diamonds/README.md)). A special effort is made to build a clean reusable pipeline for the model. Moreover, interpretability and scalability considerations are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8940fb1a-a2cd-4af7-ab97-123a04ac13e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from diamond import data\n",
    "from diamond import model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a825482",
   "metadata": {},
   "source": [
    "Data is loaded, cleaned and split as previously defined during [data exploration](data_exploration.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119985ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data.split(\n",
    "    *data.get_X_y(data.clean(data.load_raw('datasets/diamonds/diamonds.csv'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff9172a",
   "metadata": {},
   "source": [
    "All transformations and feature extractions steps defined during data exploration are here consolidated into a single pipeline, which includes:\n",
    "\n",
    "* Ordinal encoding of sequential data types: *cut*, *color*, *clarity*\n",
    "* Extraction of new features, namely: *volume*, *eccentricity*, *table distance*, *depth distance*\n",
    "* Log transformation of long tailed features: *x*, *y*, *z*, *volume* *carat*\n",
    "* Standard scaling of all features (centering and rescaling by standard deviation)\n",
    "* Feature selection (more on this later)\n",
    "\n",
    "Finally, the data is fed to a linear regression model. The target variable *price* is also log transformed, so that the internal model will learn to predict the log of the price, consistently with the log transformation over *volume*, *carat*, etc.\n",
    "\n",
    "A linear model was chosen for its bare bones interpretability. Moreover, a very high linear correlation was discovered between the diamond price and some of the input during data exploration, suggesting that a linear model is a fair fit for the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789de1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793fce9e",
   "metadata": {},
   "source": [
    "## Model tuning and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f43fb",
   "metadata": {},
   "source": [
    "The last step in the data pipeline is a feature selection step. Since we added a variety of new features, it is crucial to select only the really informative ones in order to ensure simple human interpretability of the final model. Moreover, data exploration suggested *strong collinearity* between various features, in particular *carat* and the absolute measures *x*, *y*, *z* (including the newly extracted *volume*). Strong collinearity is a potential harm to the overall explainability of the model coefficients, due to the linear dependency between features.\n",
    "\n",
    "For these reasons, feature selection is performed partially in a manual fashion, hand picking feature sets that minimize collinearity and that preserve simple interpretability. Different feature sets are hand picked and then automatically evaluated using a grid search with cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = model.make_params(model.DEFAULT_USER_PARAMETER_GRID)\n",
    "print('Feature sets')\n",
    "model.DEFAULT_USER_PARAMETER_GRID['selector']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187436a8",
   "metadata": {},
   "source": [
    "Most of the selected feature sets include the 4Cs, as they are probably the most well known diamond grading parameters. Given the strong correlation between *volume* and *carat*, they are eventually swapped but never present at the same time. Other absolute measures are never included, as they are considered condensed within *volume*. *cut* is eventually swapped with proportion parameters which have a strong correlation with it (*table*, *depth_distance*, *eccentricity*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2b508c",
   "metadata": {},
   "source": [
    "Each selector is evaluated through 5-fold cross validation, using R2 as scoring index. Instead of blindly settling with the best scoring setup, we will make some considerations on the tradeoff between interpretability and performance.\n",
    "\n",
    "In order to provide extra interpretability, it would be desirable if the model could have positive only coefficients. Given that the 4Cs can be seen as scales representing the \"quality\" of the gem, it makes sense to express the value of the gem as a direct consequence of them. Clearly, the same cannot be said of other features, such as defects (eccentricity, table distance, etc.) which can naturally be seen as detractors for the final gem value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74586c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = (\n",
    "    parameter_grid | {'linear__regressor__positive': (True, False)})\n",
    "\n",
    "search = GridSearchCV(model.pipeline, scoring='r2', param_grid=parameter_grid,\n",
    "                      refit=True, return_train_score=True)\n",
    "search.fit(X_train, y_train)\n",
    "print('Best test R2:', search.best_score_,\n",
    "      'On a train R2 of:', search.cv_results_['mean_train_score']\n",
    "                                             [search.best_index_],\n",
    "      'Achieved with params:', search.best_params_, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bbc711",
   "metadata": {},
   "source": [
    "Best performance is achieved with a setup using the 4Cs, but the cut grade is replaced with finer properties: *table*, *depth_distance*, *eccentricity*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9f393",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {'coefficients':\n",
    "     search.best_estimator_.named_steps['linear'].regressor_.coef_},\n",
    "    index=search.best_estimator_.named_steps['selector'].transformers[-1][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4501d25c",
   "metadata": {},
   "source": [
    "Model coefficients display how the 3Cs have a positive impact on the final price, while *table*, *depth_distance* and *eccentricity* are considered small defects, and indeed make use of negative coefficients. These coefficients give an idea of which property is more important than which, but they cannot be directly interpreted as some of these values undergo log transformations. We will see later some visualization that can help the final user understand the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d928f",
   "metadata": {},
   "source": [
    "Let's take a deeper look at the grid search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf9aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prettify selectors for visualization\n",
    "param_selectors = [selector.transformers[-1][-1] for selector\n",
    "                   in search.cv_results_['param_selector']]\n",
    "columns = ['mean_test_score', 'mean_train_score',\n",
    "           'param_linear__regressor__positive', 'param_selector']\n",
    "\n",
    "cv_results_df = pd.DataFrame(search.cv_results_\n",
    "                             | {'param_selector': param_selectors})[columns]\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdbfe79",
   "metadata": {},
   "source": [
    "The model reaches satisfying results even with a minimal set of input features. The very high correlations that *carat* and *volume* have with the target variable play a big part. In particular, results are competitive even in setups were coefficients are strictly positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74425560",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df.iloc[\n",
    "    cv_results_df.groupby(['param_linear__regressor__positive'])\n",
    "                 .idxmax(numeric_only=True).mean_test_score]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4340dac1",
   "metadata": {},
   "source": [
    "Inpsecting the best scoring setup for positive only coefficients confirms that it is quite competitive with the overall best setup. Performance is slightly degraded, but interpretability improves dramatically thanks to the model comprising the 4Cs with positive only weights.\n",
    "\n",
    "This model, from now on called `linear4C-positive`, is the our main proposal to Don Francesco."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea7ad3a",
   "metadata": {},
   "source": [
    "## Model interpretation\n",
    "We fit `linear4C-positive`, observe its coefficients and provide a simple visualization tool that can help Don Francesco and his customers understanding the model's behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f293c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pipeline.set_params(\n",
    "    **model.make_params({'selector': ('carat', 'cut', 'color', 'clarity'),\n",
    "                         'linear__regressor__positive': True},\n",
    "                        grid=False))\n",
    "model.pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Coefficients\n",
    "pd.DataFrame(\n",
    "    {'coefficients':\n",
    "     model.pipeline.named_steps['linear'].regressor_.coef_},\n",
    "    index=model.pipeline.named_steps['selector'].transformers[-1][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75f59c",
   "metadata": {},
   "source": [
    "Positive coefficients give a nice idea of the relative importance of the features. The cut grade has a poor impact on the final price of the diamond, despite sometimes being considered the most important C (see data exploration). Once again, since some of the input features are transformed differently, their real relationship with the target variable cannot directly be interpreted by a human customer.\n",
    "\n",
    "Here we report the partial dependency plot, giving a visual representation of the effect of each feature on the final price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcce02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trans = data.sequential_encoder.fit_transform(X_train)\n",
    "\n",
    "_, ax = plt.subplots(figsize=(10, 7))\n",
    "PartialDependenceDisplay.from_estimator(model.pipeline[1:], X_trans,\n",
    "                                        ('carat', 'cut', 'color', 'clarity'),\n",
    "                                        kind='both', centered=True, ax=ax,\n",
    "                                        n_cols=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d61124",
   "metadata": {},
   "source": [
    "Here we also report an unbiased estimate of the model's performance, evaluating on a holdout of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac1228",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pipeline.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
